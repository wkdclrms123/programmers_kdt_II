{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "!pip install -q tensorflow-hub\n",
    "!pip install -q tensorflow-datasets\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "embedding = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\")\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[],\n",
    "                           dtype=tf.string, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_length = 1000\n",
    "embed_size = 128\n",
    "\n",
    "class Encode_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.embedding = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\")\n",
    "        self.hub_layer = hub.KerasLayer(self.embedding, input_shape=[], dtype=tf.string, trainable=False)\n",
    "    def call(self, inputs):\n",
    "        words = tf.strings.split(inputs)\n",
    "        A = tf.ragged.map_flat_values(self.hub_layer, words)\n",
    "        A = A * 1\n",
    "        B = A.to_tensor(shape=[None, input_length, embed_size], default_value=0)\n",
    "        return B\n",
    "        \n",
    "encode_layer = Encode_Layer()\n",
    "\n",
    "filter_sizes = '1,2,3'\n",
    "num_filters = 1000\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "embed = encode_layer(input)\n",
    "embed = tf.expand_dims(embed, -1)\n",
    "pool_outputs = []\n",
    "for filter_size in list(map(int, filter_sizes.split(','))):\n",
    "    filter_shape = (filter_size, embed_size)\n",
    "    conv = tf.keras.layers.Conv2D(num_filters, filter_shape, strides=(1, 1), padding='valid',\n",
    "                               data_format='channels_last', activation='relu',\n",
    "                               kernel_initializer='glorot_normal',\n",
    "                               bias_initializer=tf.keras.initializers.constant(0.1),\n",
    "                               name='convolution_{:d}'.format(filter_size))(embed)\n",
    "    max_pool_shape = (input_length - filter_size + 1, 1)\n",
    "    pool = tf.keras.layers.MaxPool2D(pool_size=max_pool_shape,\n",
    "                                  strides=(1, 1), padding='valid',\n",
    "                                  data_format='channels_last',\n",
    "                                  name='max_pooling_{:d}'.format(filter_size))(conv)\n",
    "    pool_outputs.append(pool)\n",
    "pool_outputs = tf.keras.layers.concatenate(pool_outputs, axis=-1, name='concatenate')\n",
    "pool_outputs = tf.keras.layers.Flatten(data_format='channels_last', name='flatten')(pool_outputs)\n",
    "pool_outputs = tf.keras.layers.Dropout(0.4, name='dropout1')(pool_outputs)\n",
    "dense = tf.keras.layers.Dense(256)(pool_outputs)\n",
    "dense = tf.keras.layers.Dropout(0.4, name='dropout2')(dense)\n",
    "outputs = tf.keras.layers.Dense(1)(dense)\n",
    "model = tf.keras.models.Model(inputs=[input],outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"text_cnn.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data.shuffle(10000).batch(64),\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_data.batch(64),\n",
    "                    callbacks=[checkpoint_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"text_cnn.h5\", custom_objects={\"Encode_Layer\": Encode_Layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data.batch(32), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, \"text_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.saved_model.load(\"text_cnn\")\n",
    "y_pred = saved_model(tf.constant([\"this is a terrible movie.\",\"this is a good movie.\",\"very interesting movie\",\"i wouldn't watch this movie.\",\"i recommend this movie.\"]))\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
